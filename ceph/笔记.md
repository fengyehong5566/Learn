ceph挂载有两种方式：
  1、内核挂载
    mount -t ceph  mon1:port,mon2:port:/  /mountPoint  -o name=admin,secret=xxxxxxxx
    
  2、ceph-fuse 挂载方式：
    ceph-fuse -c ceph.conf -k ceph.client.admin.keyring -m mon1:port,mon2:port -r /  /mountPoint
    -r：把文件系统内的 root_directory 作为根挂载，而不是整个 Ceph 文件系统树。
    -c：指定配置文件
    -m：连接到指定监视器，而不是从ceph.conf里找
    
    -d：启动后将脱离终端、进入守护状态
    
  注：内核挂载方式性能会比较好，但会影响内核的稳定性，
      ceph-fuse是在用户空间操作，性能有损，但不会影响性能
      
  
  #挂载
sudo ceph-fuse -m 10.1.xx.231:6789,10.1.xx.232:6789,10.1.xx.233:6789 -r /MySQL-BK /data/backup
#卸载
sudo fusermount -zu /mnt/cephfs/
  
 
# ceph集群的运行状态
	1、ceph  health detail
	2、ceph  -s
	3、ceph -w  
 
# 集群flag操作
 
 
# ceph集群标志							                  说明
		noup flag(s) set：OSD启动时，会将自己在MON上标识为UP状态，设置该标准位不会被自动标识为UP状态
		nodown flag(s) set：OSD停止时，MON会将OSD标识为down状态，设置该标准位MON不会将OSD表示为down状态
	以上两个标准可以防止网络抖动

		noout flag(s) set：设置该标志位，则mon不会从crush映射中删除任何OSD。对OSD作维护时，可设置该标志位，以防止CRUSH在OSD停止时自动重平衡数据。OSD重新启动时，需要清除该flag
		noin flag(s) set：设置该标志位，可以防止数据被自动分配到OSD上
		
		norecover flag(s) set：设置该flag，禁止任何集群恢复操作。在执行维护和停机时，可设置该flag
		
	noscrub flag(s) set：禁止清理操作。清理PG会在短期内影响OSD的操作。在低带宽集群中，清理期间如果OSD的速度过慢，则会被标记为down。可以该标记来防止这种情况发生
	nodeep-scrub flag(s) set：禁止集群进行深度清洗操作
	
	norebalance flag(s) set：禁止重平衡数据。在执行集群维护或者停机时，可以使用该flag
	full flag(s) set：标记集群已满，将拒绝任何数据写入，但可读
	pause flag(s) set：集群将会阻止读写操作，但不会影响集群的in、out、up或down状态。集群扔保持正常运行,就是客户端无法读写【设置该标志位，则集群停止读写，但不影响osd自检】
	nobackfill flag(s) set：防止集群进行数据回填操作


notieragent flag(s) set							
osds exist in the crush map but not in the osdmap							osd crush weight有值但是osd weight无值
application not enabled on 1 pool(s)							没有定义池的使用类型
osds have slow requests							慢查询
Monitor clock skew detected							时钟偏移
bigdata failing to advance its oldest client/flush tid							客户端和MDS服务器之间通信使用旧的tid
Many clients (34) failing to respond to cache pressure							如果某个客户端的响应时间超过了 mds_revoke_cap_timeout （默认为 60s ）这条消息就会出现
mons down, quorum							Ceph Monitor down
in osds are down							OSD down后会出现
cache pools are missing hit_sets							使用cache tier后会出现
has mon_osd_down_out_interval set to 0							has mon_osd_down_out_interval set to 0
is full							pool满后会出现
near full osd							near full osd
unscrubbed pgs							有些pg没有scrub
pgs stuck							PG处于一些不健康状态的时候，会显示出来
requests are blocked							slow requests会警告
osds have slow requests							slow requests会警告
recovery							需要recovery的时候会报
at/near target max							使用cache tier的时候会警告
too few PGs per OSD							每个OSD的PG数过少
too many PGs per OSD							too many PGs per OSD
> pgp_num							> pgp_num
has many more objects per pg than average (too few pgs?)							每个Pg上的objects数过多
no osds							部署完就可以看到，运行过程中不会出现
full osd							OSD满时出现
pgs are stuck inactive for more than							Pg处于inactive状态，该Pg读写都不行
scrub errors							scrub 错误出现，是scrub错误?还是scrub出了不一致的pg
							
							

# 存储设备
	DAS：IDE，SATA，SCSI，SAS，USB
	NAS：NFS，CIFS
	SAN：SCSI，FC SAN，iSCSI


